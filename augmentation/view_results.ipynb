{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVC for data augmentation - results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest, wilcoxon, ttest_1samp, shapiro\n",
    "import pingouin as pg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ertk.stats import holm_bonferroni\n",
    "\n",
    "sns.set_color_codes()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stderr_str(x):\n",
    "    return f\"{x.mean():.1f} ({x.sem():.1f})\"\n",
    "\n",
    "def mean_str(x):\n",
    "    return f\"{x.mean():.1f}\"\n",
    "\n",
    "def latex(df: pd.DataFrame):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].str.replace(\"+-\", \"$\\\\pm$\", regex=False).str.replace(\"_\", \"\\\\_\", regex=False)\n",
    "    return df.to_latex(index=True, escape=False, sparsify=True)\n",
    "\n",
    "RENAMES = {\n",
    "    # Features\n",
    "    \"wav2vec_c_mean\": \"Wav2vec\",\n",
    "    \"wav2vec2_audeering_ft_c_mean\": \"Wav2vec2 FT\",\n",
    "    # Experiment\n",
    "    \"esd_test\": \"ESD\",\n",
    "    \"cross_corpus_explicit_4class_test\": \"CC explicit\",\n",
    "    \"cross_corpus_induced_4class_test\": \"CC induced\",\n",
    "    # Direction\n",
    "    \"en_zh\": \"en to zh\",\n",
    "    \"zh_en\": \"zh to en\",\n",
    "    \"CREMA-D_EmoV-DB\": \"CREMA-D to EmoV-DB\",\n",
    "    \"EmoV-DB_CREMA-D\": \"EmoV-DB to CREMA-D\",\n",
    "    \"IEMOCAP_MSP-IMPROV\": \"IEMOCAP to MSP-IMPROV\",\n",
    "    \"MSP-IMPROV_IEMOCAP\": \"MSP-IMPROV to IEMOCAP\",\n",
    "    # Augmented data\n",
    "    \"ESD_en_evc\": \"ESD en (10lang)\",\n",
    "    \"ESD_zh_evc\": \"ESD zh (10lang)\",\n",
    "    \"CREMA-D_evc\": \"CREMA-D (10lang)\",\n",
    "    \"EmoV-DB_evc\": \"EmoV-DB (10lang)\",\n",
    "    \"IEMOCAP_evc\": \"IEMOCAP (10lang)\",\n",
    "    \"MSP-IMPROV_evc\": \"MSP-IMPROV (10lang)\",\n",
    "    #\n",
    "    \"aug_method\": \"Aug. method\",\n",
    "    \"aug_data\": \"Aug. data\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get added train size experiments\n",
    "df_added = []\n",
    "for csv in Path(\"./results/lr_rep20_max_train/\").glob(\"*/*/*/*.csv\"):\n",
    "    if csv.parent.name.endswith(\"_const\") or csv.parent.name.endswith(\"_neutral\"):\n",
    "        continue\n",
    "    src, tgt, _, aug, *_ = csv.stem.split(\"_\")\n",
    "    if src == tgt:\n",
    "        continue\n",
    "    df = pd.read_csv(csv)\n",
    "    df[\"dir\"] = f\"{src}_{tgt}\"\n",
    "    df[\"aug_method\"] = aug\n",
    "    df[\"aug_data\"] = csv.parts[-2]\n",
    "    df[\"common_phones\"] = \"ipa\" in csv.parts[-2]\n",
    "    df[\"exp\"] = csv.parts[-3]\n",
    "    df[\"features\"] = csv.parts[-4]\n",
    "    df_added.append(df)\n",
    "df_added = pd.concat(df_added).set_index([\"exp\", \"aug_data\", \"common_phones\", \"features\", \"dir\", \"aug_method\", \"p_real\", \"p_fake\", \"max_train\", \"rep\"]).sort_index()\n",
    "df_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fixed train size experiments\n",
    "df_fixed = []\n",
    "for csv in Path(\"./results/lr_rep20_max_train/\").glob(\"*/*/*_const/*.csv\"):\n",
    "    if csv.parent.name.startswith(\"noaug\"):\n",
    "        continue\n",
    "    src, tgt, _, aug, *_ = csv.stem.split(\"_\")\n",
    "    if src == tgt:\n",
    "        continue\n",
    "    df = pd.read_csv(csv)\n",
    "    df[\"dir\"] = f\"{src}_{tgt}\"\n",
    "    df[\"aug_method\"] = aug\n",
    "    df[\"aug_data\"] = csv.parts[-2].rsplit(\"_\", maxsplit=1)[0]\n",
    "    df[\"common_phones\"] = \"ipa\" in csv.parts[-2]\n",
    "    df[\"exp\"] = csv.parts[-3]\n",
    "    df[\"features\"] = csv.parts[-4]\n",
    "    df_fixed.append(df)\n",
    "df_fixed = pd.concat(df_fixed).set_index([\"exp\", \"aug_data\", \"common_phones\", \"features\", \"dir\", \"aug_method\", \"p_real\", \"p_fake\", \"max_train\", \"rep\"]).sort_index()\n",
    "df_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neutral-only fixed train size experiments\n",
    "df_neutral = []\n",
    "for csv in Path(\"./results/lr_rep20_max_train/\").glob(\"*/*/*_const_neutral/*.csv\"):\n",
    "    if csv.parent.name.startswith(\"noaug\"):\n",
    "        continue\n",
    "    src, tgt, which, aug, *_ = csv.stem.split(\"_\")\n",
    "    if src == tgt:\n",
    "        continue\n",
    "    df = pd.read_csv(csv)\n",
    "    df[\"dir\"] = f\"{src}_{tgt}\"\n",
    "    df[\"aug_method\"] = f\"{which[3:]}_{aug}\"\n",
    "    aug_data = csv.parts[-2].rsplit(\"_\", maxsplit=2)[0]\n",
    "    df[\"aug_data\"] = aug_data\n",
    "    df[\"common_phones\"] = \"ipa\" in aug_data\n",
    "    df[\"exp\"] = csv.parts[-3]\n",
    "    df[\"features\"] = csv.parts[-4]\n",
    "    df_neutral.append(df)\n",
    "df_neutral = pd.concat(df_neutral).set_index([\"exp\", \"aug_data\", \"common_phones\", \"features\", \"dir\", \"aug_method\", \"p_real\", \"p_fake\", \"max_train\", \"rep\"]).sort_index()\n",
    "df_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real data fixed train size experiments\n",
    "df_real = []\n",
    "for csv in Path(\"./results/lr_rep20_max_train/\").glob(\"*/*/noaug_const/*.csv\"):\n",
    "    src, tgt, _, aug, *_ = csv.stem.split(\"_\")\n",
    "    if src == tgt:\n",
    "        continue\n",
    "    df = pd.read_csv(csv)\n",
    "    df[\"dir\"] = f\"{src}_{tgt}\"\n",
    "    df[\"aug_method\"] = aug\n",
    "    df[\"aug_data\"] = csv.parts[-2].rsplit(\"_\", maxsplit=2)[0]\n",
    "    df[\"exp\"] = csv.parts[-3]\n",
    "    df[\"features\"] = csv.parts[-4]\n",
    "    df_real.append(df)\n",
    "df_real = pd.concat(df_real).set_index([\"exp\", \"aug_data\", \"features\", \"dir\", \"aug_method\", \"p_real\", \"p_fake\", \"max_train\", \"rep\"]).sort_index()\n",
    "df_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real neutral-only data fixed train size experiments\n",
    "df_real_neutral = []\n",
    "for csv in Path(\"./results/lr_rep20_max_train/\").glob(\"*/*/noaug_const_neutral/*.csv\"):\n",
    "    src, tgt, which, aug, *_ = csv.stem.split(\"_\")\n",
    "    if src == tgt:\n",
    "        continue\n",
    "    df = pd.read_csv(csv)\n",
    "    df[\"dir\"] = f\"{src}_{tgt}\"\n",
    "    df[\"aug_method\"] = f\"{which[4:]}_{aug}\"\n",
    "    df[\"aug_data\"] = csv.parts[-2].rsplit(\"_\", maxsplit=2)[0]\n",
    "    df[\"exp\"] = csv.parts[-3]\n",
    "    df[\"features\"] = csv.parts[-4]\n",
    "    df_real_neutral.append(df)\n",
    "df_real_neutral = pd.concat(df_real_neutral).set_index([\"exp\", \"aug_data\", \"features\", \"dir\", \"aug_method\", \"p_real\", \"p_fake\", \"max_train\", \"rep\"]).sort_index()\n",
    "df_real_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get within-group fixed train size experiments\n",
    "df_within = []\n",
    "for csv in Path(\"./results/lr_rep20_max_train/\").glob(\"*/*/*_const/*.csv\"):\n",
    "    if csv.parent.name.startswith(\"noaug\"):\n",
    "        continue\n",
    "    src, tgt, _, aug, *_ = csv.stem.split(\"_\")\n",
    "    if src != tgt:\n",
    "        continue\n",
    "    df = pd.read_csv(csv)\n",
    "    df[\"dir\"] = src\n",
    "    df[\"aug_method\"] = \"within\"\n",
    "    aug_data = csv.parts[-2].rsplit(\"_\", maxsplit=1)[0]\n",
    "    df[\"aug_data\"] = aug_data\n",
    "    df[\"common_phones\"] = \"ipa\" in aug_data\n",
    "    df[\"exp\"] = csv.parts[-3]\n",
    "    df[\"features\"] = csv.parts[-4]\n",
    "    df_within.append(df)\n",
    "df_within = pd.concat(df_within).set_index([\"exp\", \"aug_data\", \"common_phones\", \"features\", \"dir\", \"aug_method\", \"p_real\", \"p_fake\", \"max_train\", \"rep\"]).sort_index()\n",
    "df_within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cross-validated emotional expressiveness for real and augmented data\n",
    "# df_cv_aug = []\n",
    "# for csv in Path(\"./results/within/\").glob(\"*/*/*/*.csv\"):\n",
    "#     df = pd.read_csv(csv).drop(columns=[\"rep\"])\n",
    "#     df[\"data\"] = csv.stem\n",
    "#     aug_data = csv.parts[-2]\n",
    "#     df[\"aug_data\"] = aug_data\n",
    "#     aug_data_source = aug_data.split(\"_\")[0]\n",
    "#     if aug_data_source == \"ESD\":\n",
    "#         aug_data_source = aug_data.split(\"_\")[1]\n",
    "#     if aug_data_source == \"noaug\":\n",
    "#         aug_data_source = csv.stem\n",
    "#     df[\"same_aug\"] = aug_data_source == csv.stem\n",
    "#     df[\"common_phones\"] = \"ipa\" in csv.parts[-2]\n",
    "#     df[\"exp\"] = csv.parts[-4]\n",
    "#     df[\"features\"] = csv.parts[-3]\n",
    "#     df_cv_aug.append(df)\n",
    "# df_cv_aug = pd.concat(df_cv_aug).set_index([\"data\", \"aug_data\", \"common_phones\", \"same_aug\", \"features\", \"data\", \"exp\", \"fold\"]).sort_index()\n",
    "# df_cv_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots with neutral and real target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = \"wav2vec2_audeering_ft_c_mean\"\n",
    "\n",
    "def plot_effects(exp, features, aug, dir, ax):\n",
    "    sns.pointplot(ax=ax, data=df_real_neutral.loc[exp, \"noaug\", features, dir, \"all_target\"].reset_index() * 100, x=\"p_real\", y=\"uar\", color=\"r\", markers='.', linestyles=\"--\", scale=0.5, errwidth=2, capsize=0.1)\n",
    "    sns.pointplot(ax=ax, data=df_real_neutral.loc[exp, \"noaug\", features, dir, \"neutral_target\"].reset_index() * 100, x=\"p_real\", y=\"uar\", color=\"orange\", linestyles=\"-.\", markers='.', scale=0.5, errwidth=2, capsize=0.1)\n",
    "    sns.pointplot(ax=ax, data=df_neutral.loc[exp, aug, features, dir, \"neutral_target\"].reset_index() * 100, x=\"p_real\", y=\"uar\", color=\"g\", markers='.', linestyles=\":\", scale=0.5, errwidth=2, capsize=0.1)\n",
    "    sns.pointplot(ax=ax, data=df_neutral.loc[exp, aug, features, dir, \"all_target\"].reset_index() * 100, x=\"p_real\", y=\"uar\", color=\"b\", markers='.', linestyles=\"-\", scale=0.5, errwidth=2, capsize=0.1)\n",
    "    # sns.pointplot(ax=ax, data=df_neutral.loc[exp, aug, features, dir, \"neutral_source\"].reset_index() * 100, x=\"p_real\", y=\"uar\", color=\"gray\", markers='.', scale=0.5)\n",
    "    # sns.pointplot(ax=ax, data=df_neutral.loc[exp, aug, features, dir, \"all_source\"].reset_index() * 100, x=\"p_real\", y=\"uar\", color=\"pink\", markers='.', scale=0.5)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3), sharex=True, sharey=True, gridspec_kw={\"hspace\": 0.25, \"wspace\": 0.05})\n",
    "plot_effects(\"cross_corpus_explicit_4class_test\", \"wav2vec2_audeering_ft_c_mean\", \"CREMA-D_ipa_spk_emo\", \"CREMA-D_EmoV-DB\", ax=ax[0])\n",
    "ax[0].set_title(\"CR to EV, Wav2vec FT\")\n",
    "ax[0].set_ylim(35, 80)\n",
    "ax[0].set_ylabel(\"UAR\")\n",
    "plot_effects(\"esd_test\", \"wav2vec2_audeering_ft_c_mean\", \"ESD_en_ipa_spk_emo\", \"en_zh\", ax=ax[1])\n",
    "ax[1].set_title(\"en to zh, Wav2vec2 FT\")\n",
    "ax[1].set_ylabel(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation with real and augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_aug_mean = (\n",
    "    (df_cv_aug * 100)\n",
    "    .rename(index=RENAMES)\n",
    "    .reindex([True, False], level=\"same_aug\")\n",
    "    .groupby([\"data\", \"aug_data\", \"features\"])[\"uar\"]\n",
    "    .mean()\n",
    "    .apply(lambda x: f\"{x:.1f}\")\n",
    "    .unstack(\"features\")\n",
    ")\n",
    "print(df_cv_aug_mean.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper bound on transfer (using real target data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df_real.droplevel([\"max_train\", \"p_fake\", \"aug_data\", \"aug_method\"])\n",
    "diff = sub_df.loc[:, :, :, 0.9][\"uar\"].sub(sub_df.loc[:, :, :, 1.0][\"uar\"]) * 100\n",
    "print(\"UAR by experiment and feature using 10% augmented data\")\n",
    "print(diff.groupby([\"dir\", \"features\"]).agg(stderr_str).rename(index=RENAMES).unstack().to_string())\n",
    "\n",
    "sub_df = df_real.droplevel([\"max_train\", \"p_fake\", \"aug_data\", \"aug_method\"])\n",
    "diff = sub_df.loc[:, :, :, 0.75][\"uar\"].sub(sub_df.loc[:, :, :, 1.0][\"uar\"]) * 100\n",
    "print(\"UAR by experiment and feature using 25% augmented data\")\n",
    "print(diff.groupby([\"dir\", \"features\"]).agg(stderr_str).rename(index=RENAMES).unstack().to_string())\n",
    "\n",
    "sub_df = df_real.droplevel([\"max_train\", \"p_fake\", \"aug_data\", \"aug_method\"])\n",
    "diff = sub_df.loc[:, :, :, 0.5][\"uar\"].sub(sub_df.loc[:, :, :, 1.0][\"uar\"]) * 100\n",
    "print(\"UAR by experiment and feature using 50% augmented data\")\n",
    "print(diff.groupby([\"dir\", \"features\"]).agg(stderr_str).rename(index=RENAMES).unstack().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean diff between 10% aug and none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = (\n",
    "    df_fixed.drop(\n",
    "        index=[\n",
    "            \"esd_train\",\n",
    "            \"eng_cross_country_explicit_4class\",\n",
    "            \"cross_corpus_induced_4class_test\",\n",
    "            \"cross_corpus_explicit_4class_nojosh\",\n",
    "        ],\n",
    "        level=\"exp\",\n",
    "    )\n",
    "    .drop(\n",
    "        index=[\n",
    "            (\"cross_corpus_induced_4class\", \"ESD_en_spk_emo\"),\n",
    "            (\"cross_corpus_explicit_4class\", \"ESD_en_spk_emo\"),\n",
    "        ]\n",
    "    )\n",
    "    .droplevel(\"p_fake\")\n",
    "    .xs(1.0, level=\"max_train\")\n",
    ")\n",
    "\n",
    "diff = sub_df.loc[:, :, :, :, :, 0.9][\"uar\"].sub(sub_df.loc[:, :, :, :, :, 1.0][\"uar\"]) * 100\n",
    "diff = diff.rename(index=RENAMES)\n",
    "print(\"UAR by experiment and augment method\")\n",
    "print(diff.groupby([\"exp\", \"dir\", \"aug_method\"]).agg(stderr_str).unstack().to_string())\n",
    "print(\"UAR by experiment and feature\")\n",
    "print(diff.groupby([\"exp\", \"dir\", \"features\"]).agg(stderr_str).unstack().to_string())\n",
    "\n",
    "df_aug = (\n",
    "    diff[diff.index.get_level_values(\"aug_method\").isin([\"source\", \"target\"])]\n",
    "    .groupby([\"exp\", \"dir\", \"aug_data\", \"features\", \"aug_method\"])\n",
    "    .agg(stderr_str)\n",
    "    .unstack([\"features\", \"aug_method\"])\n",
    ")\n",
    "print(\"UAR by experiment and feature\")\n",
    "print(df_aug.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean diff between best replacement aug and none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_p_real(x):\n",
    "    best = x.unstack(\"rep\").mean(1).unstack(\"p_real\").idxmax(1).item()\n",
    "    return x.xs(best, level=\"p_real\").droplevel(x.index.names[:-2])\n",
    "\n",
    "\n",
    "def arg_best_p_real(x):\n",
    "    return x.unstack(\"rep\").mean(1).unstack(\"p_real\").idxmax(1).item()\n",
    "\n",
    "\n",
    "sub_df = (\n",
    "    df_fixed.drop(\n",
    "        index=[\n",
    "            \"esd_train\",\n",
    "            \"eng_cross_country_explicit_4class\",\n",
    "            \"cross_corpus_induced_4class\",\n",
    "            \"cross_corpus_explicit_4class\",\n",
    "            \"cross_corpus_explicit_4class_nojosh\",\n",
    "        ],\n",
    "        level=\"exp\",\n",
    "    )\n",
    "    .drop(\n",
    "        index=[\n",
    "            (\"cross_corpus_induced_4class\", \"ESD_en_spk_emo\"),\n",
    "            (\"cross_corpus_explicit_4class\", \"ESD_en_spk_emo\"),\n",
    "        ],\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "    .drop(index=False, level=\"common_phones\")\n",
    "    .droplevel(\"p_fake\")\n",
    "    .xs(1.0, level=\"max_train\")\n",
    ")\n",
    "\n",
    "fixed_argbest = (\n",
    "    sub_df.drop(1.0, level=\"p_real\")\n",
    "    .groupby(level=[\"dir\", \"aug_data\", \"features\", \"aug_method\"])[\"uar\"]\n",
    "    .apply(arg_best_p_real)\n",
    ")\n",
    "\n",
    "best_df = (\n",
    "    sub_df.drop(1.0, level=\"p_real\")\n",
    "    .groupby(level=[\"aug_data\", \"features\", \"dir\", \"aug_method\"])[\"uar\"]\n",
    "    .apply(best_p_real)\n",
    ")\n",
    "base_df = sub_df.xs(1.0, level=\"p_real\")[\"uar\"]\n",
    "\n",
    "diff = (best_df - base_df) * 100\n",
    "\n",
    "sig_idx = []\n",
    "for idx, group in diff.drop(index=\"both\", level=\"aug_method\").groupby(\n",
    "    [\"dir\", \"aug_data\", \"features\", \"aug_method\"]\n",
    "):\n",
    "    print(shapiro(group))\n",
    "    res = pg.ttest(group, 0, alternative=\"two-sided\")\n",
    "    if res[\"p-val\"].item() < 0.05 / 48:\n",
    "        print(idx)\n",
    "        sig_idx.append(idx)\n",
    "\n",
    "print(\n",
    "    (df_within * 100).drop(index=False, level=\"common_phones\")\n",
    "    .droplevel(\"p_fake\")\n",
    "    .xs(1.0, level=\"max_train\")\n",
    "    .xs(1.0, level=\"p_real\")[\"uar\"]\n",
    "    .groupby([\"dir\", \"aug_data\", \"features\"])\n",
    "    .agg(stderr_str)\n",
    "    .rename(index=RENAMES)\n",
    "    .sort_index()\n",
    "    .unstack(\"features\")\n",
    "    .to_string()\n",
    ")\n",
    "\n",
    "print(\"Baseline\")\n",
    "print(\n",
    "    (base_df * 100)\n",
    "    .drop(\"both\", level=\"aug_method\")\n",
    "    .groupby([\"dir\", \"aug_data\", \"features\"])\n",
    "    .agg(stderr_str)\n",
    "    .rename(index=RENAMES)\n",
    "    .sort_index()\n",
    "    .unstack(\"features\")\n",
    "    .to_string()\n",
    ")\n",
    "print()\n",
    "\n",
    "df_diff_best_fixed_aug = (\n",
    "    diff.rename(index=RENAMES)\n",
    "    .drop(index=\"both\", level=\"aug_method\")\n",
    "    .groupby([\"dir\", \"aug_data\", \"features\", \"aug_method\"])\n",
    "    .agg(stderr_str)\n",
    "    .unstack([\"features\", \"aug_method\"])\n",
    ")\n",
    "print(\"UAR by experiment and feature\")\n",
    "print(df_diff_best_fixed_aug.to_string())\n",
    "print()\n",
    "\n",
    "print(\"Max p_real\")\n",
    "print(\n",
    "    fixed_argbest.drop(\"both\", level=\"aug_method\")\n",
    "    .rename(index=RENAMES)\n",
    "    .sort_index()\n",
    "    .unstack([\"features\", \"aug_method\"])\n",
    "    .to_string()\n",
    ")\n",
    "print(fixed_argbest.loc[sig_idx].value_counts())\n",
    "print()\n",
    "\n",
    "print(\"UAR by experiment and augment method\")\n",
    "# target_source = diff.xs(\"target\", level=\"aug_method\") - diff.xs(\n",
    "#     \"source\", level=\"aug_method\"\n",
    "# )\n",
    "# target_source = target_source.groupby([\"dir\"]).mean()\n",
    "# print(shapiro(target_source))\n",
    "# print(pg.ttest(target_source, 0, alternative=\"greater\").to_string())\n",
    "# print(pg.compute_bootci(target_source, func=\"mean\", confidence=0.975))\n",
    "# both_target = diff.xs(\"both\", level=\"aug_method\") - diff.xs(\n",
    "#     \"target\", level=\"aug_method\"\n",
    "# )\n",
    "# both_target = both_target.groupby(\"dir\").mean()\n",
    "# print(shapiro(both_target))\n",
    "# print(pg.ttest(both_target, 0, alternative=\"greater\").to_string())\n",
    "# print(pg.compute_bootci(both_target, func=\"mean\", confidence=0.975))\n",
    "\n",
    "diff_by_aug_method = (\n",
    "    diff.rename(index=RENAMES)\n",
    "    .reindex(index=[\"source\", \"target\", \"both\"], level=\"aug_method\")\n",
    "    .groupby([\"dir\", \"aug_method\"])\n",
    "    .mean()\n",
    "    .unstack()\n",
    ")\n",
    "print(diff_by_aug_method.applymap(\"{:.1f}\".format).to_string())\n",
    "print(diff_by_aug_method.agg(stderr_str))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"UAR by experiment and feature\")\n",
    "# feature_diff = diff.xs(\"wav2vec_c_mean\", level=\"features\") - diff.xs(\n",
    "#     \"wav2vec2_audeering_ft_c_mean\", level=\"features\"\n",
    "# )\n",
    "# feature_diff = feature_diff.groupby([\"dir\"]).mean()\n",
    "# print(shapiro(feature_diff))\n",
    "# print(pg.ttest(feature_diff, 0, alternative=\"greater\").to_string())\n",
    "# print(pg.compute_bootci(feature_diff, func=\"mean\"))\n",
    "\n",
    "diff_by_features = (\n",
    "    diff.rename(index=RENAMES).groupby([\"dir\", \"features\"]).mean().unstack()\n",
    ")\n",
    "print(diff_by_features.applymap(\"{:.1f}\".format).to_string())\n",
    "print(diff_by_features.agg(stderr_str))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean diff between additional best aug and none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_p_fake(x):\n",
    "    best = x.unstack(\"rep\").mean(1).unstack(\"p_fake\").idxmax(1).item()\n",
    "    return x.xs(best, level=\"p_fake\").droplevel(\n",
    "        [\"exp\", \"aug_data\", \"features\", \"dir\", \"aug_method\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def arg_best_p_fake(x):\n",
    "    return x.unstack(\"rep\").mean(1).unstack(\"p_fake\").idxmax(1).item()\n",
    "\n",
    "\n",
    "sub_df = (\n",
    "    df_added.drop(\n",
    "        index=[\n",
    "            \"esd_train\",\n",
    "            \"eng_cross_country_explicit_4class\",\n",
    "            \"cross_corpus_induced_4class\",\n",
    "            \"cross_corpus_explicit_4class\",\n",
    "            \"cross_corpus_explicit_4class_nojosh\",\n",
    "        ],\n",
    "        level=\"exp\",\n",
    "    )\n",
    "    .droplevel([\"p_real\", \"max_train\"])\n",
    "    .drop(\n",
    "        index=[\n",
    "            (\"cross_corpus_induced_4class\", \"ESD_en_spk_emo\"),\n",
    "            (\"cross_corpus_explicit_4class\", \"ESD_en_spk_emo\"),\n",
    "        ],\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "    .drop(index=False, level=\"common_phones\")\n",
    ")\n",
    "\n",
    "arg_best = (\n",
    "    sub_df.drop(0.0, level=\"p_fake\")\n",
    "    .groupby(level=[\"dir\", \"aug_data\", \"features\", \"aug_method\"])[\"uar\"]\n",
    "    .apply(arg_best_p_fake)\n",
    ")\n",
    "best_df = (\n",
    "    sub_df.drop(0.0, level=\"p_fake\")\n",
    "    .groupby(level=[\"aug_data\", \"features\", \"dir\", \"aug_method\"])[\n",
    "        \"uar\"\n",
    "    ]\n",
    "    .apply(best_p_fake)\n",
    ")\n",
    "base_df = sub_df.xs(0.0, level=\"p_fake\")[\"uar\"]\n",
    "\n",
    "diff = (best_df - base_df) * 100\n",
    "\n",
    "for name, group in diff.rename(index=RENAMES).drop(index=\"both\", level=\"aug_method\").groupby([\"dir\", \"aug_data\", \"features\", \"aug_method\"]):\n",
    "    res = pg.ttest(group.to_numpy(), 0, alternative=\"two-sided\")\n",
    "    if res[\"p-val\"].item() < 0.05 / 24:\n",
    "        print(name)\n",
    "\n",
    "df_diff_best_add_aug = (\n",
    "    diff.rename(index=RENAMES).drop(index=\"both\", level=\"aug_method\")\n",
    "    .groupby([\"dir\", \"aug_data\", \"features\", \"aug_method\"])\n",
    "    .agg(stderr_str)\n",
    "    .unstack([\"features\", \"aug_method\"])\n",
    ")\n",
    "print(\"UAR by experiment and feature\")\n",
    "print(df_diff_best_add_aug.to_string())\n",
    "\n",
    "\n",
    "# target_source = diff.xs(\"target\", level=\"aug_method\") - diff.xs(\"source\", level=\"aug_method\")\n",
    "# target_source = target_source.groupby([\"dir\"]).mean()\n",
    "# print(shapiro(target_source))\n",
    "# print(pg.ttest(target_source, 0, alternative=\"greater\").to_string())\n",
    "# print(pg.compute_bootci(target_source, func=\"mean\"))\n",
    "# both_target = diff.xs(\"both\", level=\"aug_method\") - diff.xs(\"target\", level=\"aug_method\")\n",
    "# both_target = both_target.groupby(\"dir\").mean()\n",
    "# print(shapiro(both_target))\n",
    "# print(pg.ttest(both_target, 0, alternative=\"greater\").to_string())\n",
    "# print(pg.compute_bootci(both_target, func=\"mean\"))\n",
    "\n",
    "print(\"UAR by experiment and augment method\")\n",
    "print(diff.rename(index=RENAMES).groupby([\"dir\", \"aug_method\"]).agg(stderr_str).unstack().to_string())\n",
    "\n",
    "# feature_diff = diff.xs(\"wav2vec_c_mean\", level=\"features\") - diff.xs(\"wav2vec2_audeering_ft_c_mean\", level=\"features\")\n",
    "# feature_diff = feature_diff.groupby([\"dir\"]).mean()\n",
    "# print(shapiro(feature_diff))\n",
    "# print(pg.ttest(feature_diff, 0, alternative=\"greater\").to_string())\n",
    "# print(pg.compute_bootci(feature_diff, func=\"mean\"))\n",
    "\n",
    "print(\"UAR by experiment and feature\")\n",
    "print(diff.rename(index=RENAMES).groupby([\"dir\", \"features\"]).agg(stderr_str).unstack().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean diff between within-group best aug and none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_p_real(x):\n",
    "    best = x.unstack(\"rep\").mean(1).unstack(\"p_real\").idxmax(1).item()\n",
    "    return x.xs(best, level=\"p_real\").droplevel(x.index.names[:-2])\n",
    "\n",
    "\n",
    "def arg_best_p_real(x):\n",
    "    return x.unstack(\"rep\").mean(1).unstack(\"p_real\").idxmax(1).item()\n",
    "    \n",
    "\n",
    "sub_df = (\n",
    "    df_within.drop(\n",
    "        index=[\n",
    "            (\"IEMOCAP_test\", \"ESD_en_spk_emo\"),\n",
    "            (\"MSP-IMPROV_test\", \"ESD_en_spk_emo\"),\n",
    "        ]\n",
    "    )\n",
    "    .droplevel([\"p_fake\", \"aug_method\"])\n",
    "    .drop(index=False, level=\"common_phones\")\n",
    "    .xs(1.0, level=\"max_train\")\n",
    ")\n",
    "\n",
    "best_df = (\n",
    "    sub_df.drop(1.0, level=\"p_real\")\n",
    "    .groupby(level=[\"aug_data\", \"features\", \"dir\"])[\"uar\"]\n",
    "    .apply(best_p_real)\n",
    ")\n",
    "base_df = sub_df.xs(1.0, level=\"p_real\")[\"uar\"]\n",
    "\n",
    "diff = (best_df - base_df) * 100\n",
    "diff = diff.rename(index=RENAMES)\n",
    "\n",
    "for idx, group in diff.rename(index=RENAMES).groupby([\"aug_data\", \"features\"]):\n",
    "    res = pg.ttest(group.to_numpy(), 0, alternative=\"two-sided\")\n",
    "    if res[\"p-val\"].item() < 0.05 / 12:\n",
    "        print(idx)\n",
    "\n",
    "print(\"UAR using augmented target data, by experiment, augmented data and features\")\n",
    "within_best = diff.groupby([\"aug_data\", \"features\"]).agg(stderr_str).unstack()\n",
    "print(within_best.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of neutral vs. emotional augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_p_real(x):\n",
    "    best = x.unstack(\"rep\").mean(1).unstack(\"p_real\").idxmax(1).item()\n",
    "    return x.xs(best, level=\"p_real\").droplevel(x.index.names[:-2])\n",
    "\n",
    "\n",
    "def arg_best_p_real(x):\n",
    "    return x.unstack(\"rep\").mean(1).unstack(\"p_real\").idxmax(1).item()\n",
    "\n",
    "\n",
    "sub_df = (\n",
    "    df_neutral.drop(\n",
    "        index=[\n",
    "            \"esd_train\",\n",
    "            \"cross_corpus_explicit_4class_nojosh\",\n",
    "            \"cross_corpus_induced_4class\",\n",
    "            \"cross_corpus_explicit_4class\",\n",
    "        ],\n",
    "        level=\"exp\",\n",
    "    )\n",
    "    .drop(index=False, level=\"common_phones\")\n",
    "    .drop(\n",
    "        index=[\"all_both\", \"neutral_both\", \"all_source\", \"neutral_source\"],\n",
    "        level=\"aug_method\",\n",
    "    )\n",
    "    .droplevel(\"p_fake\")\n",
    "    .drop(1.0, level=\"p_real\")[\"uar\"]\n",
    ")\n",
    "\n",
    "arg_best = (\n",
    "    sub_df.xs(\"all_target\", level=\"aug_method\")\n",
    "    .groupby(level=[\"dir\", \"aug_data\", \"features\"])\n",
    "    .apply(arg_best_p_real)\n",
    ")\n",
    "diffs = []\n",
    "for (dir, aug_data, features), p_real in arg_best.items():\n",
    "    _df = (\n",
    "        sub_df.xs(dir, level=\"dir\", drop_level=False)\n",
    "        .xs(aug_data, level=\"aug_data\", drop_level=False)\n",
    "        .xs(features, level=\"features\", drop_level=False)\n",
    "        .xs(p_real, level=\"p_real\")\n",
    "    )\n",
    "    diffs.append(_df.xs(\"all_target\", level=\"aug_method\") - _df.xs(\n",
    "        \"neutral_target\", level=\"aug_method\"\n",
    "    ))\n",
    "diff = pd.concat(diffs)\n",
    "diff = diff * 100\n",
    "\n",
    "for idx, group in diff.rename(index=RENAMES).groupby([\"dir\", \"aug_data\", \"features\"]):\n",
    "    res = pg.ttest(group.to_numpy(), 0, alternative=\"two-sided\")\n",
    "    if res[\"p-val\"].item() < 0.05 / 12:\n",
    "        print(idx)\n",
    "\n",
    "df_emotional_neutral = diff.rename(index=RENAMES).groupby(level=[\"dir\", \"aug_data\", \"features\"]).agg(stderr_str).unstack(\"features\")\n",
    "print(df_emotional_neutral.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
