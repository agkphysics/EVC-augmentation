#!/bin/bash

# ESD en
python train.py --checkpoint_path ../pre-train/out_cv_10lang/logdir/checkpoint_84000 --warm_start --output_directory out_ESD_en --hparams batch_size=16,iters_per_checkpoint=10000,iters_per_validate=1000,distributed_run=False,training_list=../data/ESD/en/train.txt,validation_list=../data/ESD/en/valid.txt,mel_mean_std=../data/ESD/en/mel_mean_std.npy,phones_csv=../data/ESD/en/phones_ipa.csv,emo_embedding_dir=embeddings/ESD/en,\""emo_list=[anger,happiness,neutral,sadness,surprise]"\",emo_csv=../data/ESD/en/emotion.csv,pretrain_n_speakers=1967,n_symbols=315 --n_gpus 1
python convert_all.py --checkpoint_path out_ESD_en/logdir/checkpoint_65590 --input_list ../emotion/datasets/ESD/files_neutral.txt --output_dir ../augmentation/datasets/ESD_aug/ESD_en_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[anger,happiness,neutral,sadness,surprise]"\",emo_embedding_dir=embeddings/ESD/en,mel_mean_std=../data/ESD/en/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2

# ESD zh
python train.py --checkpoint_path ../pre-train/out_cv_10lang/logdir/checkpoint_84000 --warm_start --output_directory out_ESD_zh --hparams batch_size=16,iters_per_checkpoint=10000,iters_per_validate=1000,distributed_run=False,training_list=../data/ESD/zh/train.txt,validation_list=../data/ESD/zh/valid.txt,mel_mean_std=../data/ESD/zh/mel_mean_std.npy,phones_csv=../data/ESD/zh/phones_ipa.csv,emo_embedding_dir=embeddings/ESD/zh,\""emo_list=[anger,happiness,neutral,sadness,surprise]"\",emo_csv=../data/ESD/zh/emotion.csv,pretrain_n_speakers=1967,n_symbols=315 --n_gpus 1
python convert_all.py --checkpoint_path out_ESD_zh/logdir/checkpoint_65590 --input_list ../emotion/datasets/ESD/files_neutral.txt --output_dir ../augmentation/datasets/ESD_aug/ESD_zh_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[anger,happiness,neutral,sadness,surprise]"\",emo_embedding_dir=embeddings/ESD/zh,mel_mean_std=../data/ESD/zh/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2

# CREMA-D
python train.py --checkpoint_path ../pre-train/out_cv_10lang/logdir/checkpoint_84000 --warm_start --output_directory out_CREMA-D --hparams batch_size=16,iters_per_checkpoint=2000,iters_per_validate=500,distributed_run=False,training_list=../data/CREMA-D/train.txt,validation_list=../data/CREMA-D/valid.txt,mel_mean_std=../data/CREMA-D/mel_mean_std.npy,phones_csv=../data/CREMA-D/phones_ipa.csv,emo_embedding_dir=embeddings/CREMA-D,\""emo_list=[anger,disgust,fear,happiness,neutral,sadness]"\",emo_csv=../data/CREMA-D/emotion.csv,pretrain_n_speakers=1967,n_symbols=315 --n_gpus 1
python convert_all.py --checkpoint_path out_CREMA-D/logdir/checkpoint_28560 --input_list ../emotion/datasets/CREMA-D/files_neutral.txt --output_dir ../augmentation/datasets/CREMA-D_aug/CREMA-D_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[anger,disgust,fear,happiness,neutral,sadness]"\",emo_embedding_dir=embeddings/CREMA-D,mel_mean_std=../data/CREMA-D/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2
python convert_all.py --checkpoint_path out_CREMA-D/logdir/checkpoint_28560 --input_list ../emotion/datasets/EmoV-DB/files_neutral.txt --output_dir ../augmentation/datasets/EmoV-DB_aug/CREMA-D_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[anger,disgust,fear,happiness,neutral,sadness]"\",emo_embedding_dir=embeddings/CREMA-D,mel_mean_std=../data/CREMA-D/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2

# EmoV-DB
python train.py --checkpoint_path ../pre-train/out_cv_10lang/logdir/checkpoint_84000 --warm_start --output_directory out_EmoV-DB --hparams batch_size=16,iters_per_checkpoint=2000,iters_per_validate=500,distributed_run=False,training_list=../data/EmoV-DB/train.txt,validation_list=../data/EmoV-DB/valid.txt,mel_mean_std=../data/EmoV-DB/mel_mean_std.npy,phones_csv=../data/EmoV-DB/phones_ipa.csv,emo_embedding_dir=embeddings/EmoV-DB,\""emo_list=[amusement,anger,disgust,neutral,sleepiness]"\",emo_csv=../data/EmoV-DB/emotion.csv,pretrain_n_speakers=1967,n_symbols=315 --n_gpus 1
python convert_all.py --checkpoint_path out_EmoV-DB/logdir/checkpoint_23730 --input_list ../emotion/datasets/EmoV-DB/files_neutral.txt --output_dir ../augmentation/datasets/EmoV-DB_aug/EmoV-DB_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[amusement,anger,disgust,neutral,sleepiness]"\",emo_embedding_dir=embeddings/EmoV-DB,mel_mean_std=../data/EmoV-DB/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2
python convert_all.py --checkpoint_path out_EmoV-DB/logdir/checkpoint_23730 --input_list ../emotion/datasets/CREMA-D/files_neutral.txt --output_dir ../augmentation/datasets/CREMA-D_aug/EmoV-DB_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[amusement,anger,disgust,neutral,sleepiness]"\",emo_embedding_dir=embeddings/EmoV-DB,mel_mean_std=../data/EmoV-DB/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2

# MSP-IMPROV
python train.py --checkpoint_path ../pre-train/out_cv_10lang/logdir/checkpoint_84000 --warm_start --output_directory out_MSP-IMPROV --hparams batch_size=16,iters_per_checkpoint=2000,iters_per_validate=500,distributed_run=False,training_list=../data/MSP-IMPROV/train.txt,validation_list=../data/MSP-IMPROV/valid.txt,mel_mean_std=../data/MSP-IMPROV/mel_mean_std.npy,phones_csv=../data/MSP-IMPROV/phones_ipa.csv,emo_embedding_dir=embeddings/MSP-IMPROV,\""emo_list=[anger,happiness,neutral,sadness]"\",emo_csv=../data/MSP-IMPROV/emotion.csv,pretrain_n_speakers=1967,n_symbols=315 --n_gpus 1
python convert_all.py --checkpoint_path out_MSP-IMPROV/logdir/checkpoint_20650 --input_list ../emotion/datasets/MSP-IMPROV/files_neutral.txt --output_dir ../augmentation/datasets/MSP-IMPROV_aug/MSP-IMPROV_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[anger,happiness,neutral,sadness]"\",emo_embedding_dir=embeddings/MSP-IMPROV,mel_mean_std=../data/MSP-IMPROV/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2
python convert_all.py --checkpoint_path out_MSP-IMPROV/logdir/checkpoint_20650 --input_list ../emotion/datasets/IEMOCAP/files_neutral.txt --output_dir ../augmentation/datasets/IEMOCAP_aug/MSP-IMPROV_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[anger,happiness,neutral,sadness]"\",emo_embedding_dir=embeddings/MSP-IMPROV,mel_mean_std=../data/MSP-IMPROV/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2

# IEMOCAP
python train.py --checkpoint_path ../pre-train/out_cv_10lang/logdir/checkpoint_84000 --warm_start --output_directory out_IEMOCAP --hparams batch_size=16,iters_per_checkpoint=2000,iters_per_validate=500,distributed_run=False,training_list=../data/IEMOCAP/train.txt,validation_list=../data/IEMOCAP/valid.txt,mel_mean_std=../data/IEMOCAP/mel_mean_std.npy,phones_csv=../data/IEMOCAP/phones_ipa.csv,emo_embedding_dir=embeddings/IEMOCAP,\""emo_list=[anger,happiness,neutral,sadness]"\",emo_csv=../data/IEMOCAP/emotion.csv,pretrain_n_speakers=1967,n_symbols=315 --n_gpus 1
python convert_all.py --checkpoint_path out_IEMOCAP/logdir/checkpoint_13510 --input_list ../emotion/datasets/IEMOCAP/files_neutral.txt --output_dir ../augmentation/datasets/IEMOCAP_aug/IEMOCAP_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[anger,happiness,neutral,sadness]"\",emo_embedding_dir=embeddings/IEMOCAP,mel_mean_std=../data/IEMOCAP/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2
python convert_all.py --checkpoint_path out_IEMOCAP/logdir/checkpoint_13510 --input_list ../emotion/datasets/MSP-IMPROV/files_neutral.txt --output_dir ../augmentation/datasets/MSP-IMPROV_aug/IEMOCAP_evc/hifi-gan_v1_ft_cv_mel_vocoded/ --wav --hifi_gan_path ../hifi-gan/cp/v1_cv_10lang_ft_cv_10lang/g_00496000 --hparams \""emo_list=[anger,happiness,neutral,sadness]"\",emo_embedding_dir=embeddings/IEMOCAP,mel_mean_std=../data/IEMOCAP/mel_mean_std.npy,pretrain_n_speakers=1967,n_symbols=315 --neutral 2
